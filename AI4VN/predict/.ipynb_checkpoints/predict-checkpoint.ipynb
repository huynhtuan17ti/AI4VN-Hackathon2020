{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, MaxPooling2D,Dense,Dropout,BatchNormalization\n",
    "from tensorflow.keras.models  import Sequential, Model, load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img, array_to_img\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import efficientnet.tfkeras as efn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.compat.v1.keras.backend import set_session\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "set_session(sess)  # set this TensorFlow session as the default session for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 70\n",
    "IMG_SIZE = 512\n",
    "NUM_CLASSES = 7\n",
    "ROOT_PATH = '/home/ryan/Machine_Learning/AI4VN'\n",
    "MODEL_NAME = \"EfnB6_multi_label_model_combine_1.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(ROOT_PATH + '/csv_file/' + \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ryan/miniconda3/envs/tuan/lib/python3.7/logging/__init__.py\", line 1025, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/home/ryan/miniconda3/envs/tuan/lib/python3.7/logging/__init__.py\", line 869, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/home/ryan/miniconda3/envs/tuan/lib/python3.7/logging/__init__.py\", line 608, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/home/ryan/miniconda3/envs/tuan/lib/python3.7/logging/__init__.py\", line 369, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/home/ryan/miniconda3/envs/tuan/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/home/ryan/miniconda3/envs/tuan/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/ryan/miniconda3/envs/tuan/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/ryan/miniconda3/envs/tuan/lib/python3.7/site-packages/traitlets/config/application.py\", line 845, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/ryan/miniconda3/envs/tuan/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 612, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/ryan/miniconda3/envs/tuan/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 149, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/home/ryan/miniconda3/envs/tuan/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/home/ryan/miniconda3/envs/tuan/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n",
      "    handle._run()\n",
      "  File \"/home/ryan/miniconda3/envs/tuan/lib/python3.7/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/ryan/miniconda3/envs/tuan/lib/python3.7/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/home/ryan/miniconda3/envs/tuan/lib/python3.7/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/home/ryan/miniconda3/envs/tuan/lib/python3.7/site-packages/tornado/gen.py\", line 787, in inner\n",
      "    self.run()\n",
      "  File \"/home/ryan/miniconda3/envs/tuan/lib/python3.7/site-packages/tornado/gen.py\", line 748, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/home/ryan/miniconda3/envs/tuan/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 381, in dispatch_queue\n",
      "    yield self.process_one()\n",
      "  File \"/home/ryan/miniconda3/envs/tuan/lib/python3.7/site-packages/tornado/gen.py\", line 225, in wrapper\n",
      "    runner = Runner(result, future, yielded)\n",
      "  File \"/home/ryan/miniconda3/envs/tuan/lib/python3.7/site-packages/tornado/gen.py\", line 714, in __init__\n",
      "    self.run()\n",
      "  File \"/home/ryan/miniconda3/envs/tuan/lib/python3.7/site-packages/tornado/gen.py\", line 748, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/home/ryan/miniconda3/envs/tuan/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 365, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/home/ryan/miniconda3/envs/tuan/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/ryan/miniconda3/envs/tuan/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/home/ryan/miniconda3/envs/tuan/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/ryan/miniconda3/envs/tuan/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 545, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"/home/ryan/miniconda3/envs/tuan/lib/python3.7/site-packages/tornado/gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"/home/ryan/miniconda3/envs/tuan/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/home/ryan/miniconda3/envs/tuan/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/home/ryan/miniconda3/envs/tuan/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2878, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"/home/ryan/miniconda3/envs/tuan/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2923, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/home/ryan/miniconda3/envs/tuan/lib/python3.7/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/ryan/miniconda3/envs/tuan/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3147, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/home/ryan/miniconda3/envs/tuan/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/home/ryan/miniconda3/envs/tuan/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3418, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-5-497a15948219>\", line 21, in <module>\n",
      "    target_size=(IMG_SIZE, IMG_SIZE))\n",
      "  File \"/home/ryan/miniconda3/envs/tuan/lib/python3.7/site-packages/tensorflow/python/keras/preprocessing/image.py\", line 1064, in flow_from_dataframe\n",
      "    'to match the exact filenames in disk.', DeprecationWarning)\n",
      "  File \"/home/ryan/miniconda3/envs/tuan/lib/python3.7/site-packages/tensorflow/python/platform/tf_logging.py\", line 173, in warn\n",
      "    get_logger().warning(msg, *args, **kwargs)\n",
      "Message: 'has_ext is deprecated, filenames in the dataframe have to match the exact filenames in disk.'\n",
      "Arguments: (<class 'DeprecationWarning'>,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19990 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "_datagen_test_aug = ImageDataGenerator(rescale = 1./255.,\n",
    "                                  fill_mode = \"nearest\",\n",
    "                                    rotation_range=10,\n",
    "                                    width_shift_range=0.1,\n",
    "                                    height_shift_range=0.1,\n",
    "                                    brightness_range=[0.8,1.2],\n",
    "                                    zoom_range=[0.8,1.3],\n",
    "                                    horizontal_flip=True)\n",
    "\n",
    "_datagen_test = ImageDataGenerator(rescale = 1./255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator(aug = False):\n",
    "    test_generator = _datagen_test.flow_from_dataframe(\n",
    "                    dataframe=test_df,\n",
    "                    directory=ROOT_PATH +'/'+\"test\",\n",
    "                    x_col=\"image_id\",\n",
    "                    y_col=None,\n",
    "                    has_ext=True,\n",
    "                    class_mode=None,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    seed=42,\n",
    "                    shuffle=False,\n",
    "                    target_size=(IMG_SIZE, IMG_SIZE))\n",
    "    if aug:\n",
    "        test_generator = _datagen_test_aug.flow_from_dataframe(\n",
    "                    dataframe=test_df,\n",
    "                    directory=ROOT_PATH +'/'+\"test\",\n",
    "                    x_col=\"image_id\",\n",
    "                    y_col=None,\n",
    "                    has_ext=True,\n",
    "                    class_mode=None,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    seed=42,\n",
    "                    shuffle=False,\n",
    "                    target_size=(IMG_SIZE, IMG_SIZE))\n",
    "    return test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model =  efn.EfficientNetB6(weights='imagenet', include_top=False, pooling='avg', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "x = base_model.output\n",
    "_x = (Dropout(0.3))(x)\n",
    "predictions = Dense(NUM_CLASSES, activation=\"sigmoid\")(_x)\n",
    "model =  Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(ROOT_PATH + '/' + \"models/\" + MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-ba83ebc9ac06>:1: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "285/286 [============================>.] - ETA: 2sWARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "286/286 [==============================] - 681s 2s/step\n"
     ]
    }
   ],
   "source": [
    "def predict():\n",
    "    print('Starting predict ....')\n",
    "    test_generator = get_generator()\n",
    "    y_pred = model.predict_generator(test_generator, verbose = 1, workers = 4, use_multiprocessing = True)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test time augmentation\n",
    "def test_time_augmentation(num_images, repeat = 10):\n",
    "    print(\"test time augmentation with {} times\".format(repeat))\n",
    "    sum_prob = np.zeros((num_images, NUM_CLASSES))\n",
    "    test_generator = get_generator(aug = True)\n",
    "    for num in range(repeat):\n",
    "        prob = model.predict_generator(test_generator, verbose = 1, workers = 4, use_multiprocessing = True)\n",
    "        for i in range(num_images):\n",
    "            for j in range(NUM_CLASSES):\n",
    "                sum_prob[i][j] += prob[i][j]\n",
    "    for i in range(num_images):\n",
    "        for j in range(NUM_CLASSES):\n",
    "            sum_prob[i][j] /= repeat\n",
    "    return sum_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test time augmentation with 10 times\n",
      "WARNING:tensorflow:From <ipython-input-8-2d19bc2cfe46>:6: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "285/286 [============================>.] - ETA: 2sWARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "286/286 [==============================] - 663s 2s/step\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "285/286 [============================>.] - ETA: 2sWARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "286/286 [==============================] - 661s 2s/step\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "285/286 [============================>.] - ETA: 2sWARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "286/286 [==============================] - 660s 2s/step\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "285/286 [============================>.] - ETA: 2sWARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "286/286 [==============================] - 663s 2s/step\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "285/286 [============================>.] - ETA: 2sWARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "286/286 [==============================] - 660s 2s/step\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "285/286 [============================>.] - ETA: 2sWARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "286/286 [==============================] - 665s 2s/step\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "285/286 [============================>.] - ETA: 2sWARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "286/286 [==============================] - 665s 2s/step\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "285/286 [============================>.] - ETA: 2sWARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "286/286 [==============================] - 666s 2s/step\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "285/286 [============================>.] - ETA: 2sWARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "286/286 [==============================] - 664s 2s/step\n",
      "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "285/286 [============================>.] - ETA: 2sWARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
      "286/286 [==============================] - 663s 2s/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = test_time_augmentation(len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(get_pred = False):\n",
    "    image_id = []\n",
    "    label = []\n",
    "    threshold = THRESHOLD\n",
    "    y_class = np.zeros((NUM_CLASSES, len(test_df)))\n",
    "    for x in range(NUM_CLASSES):\n",
    "        y_class[x][i] = np.around(y_pred[i][x], 3)\n",
    "    for i in range(len(test_df)):\n",
    "        image_id.append(test_df['image_id'][i])\n",
    "        if max(y_pred[i]) < threshold:\n",
    "            label.append(0)\n",
    "        else:\n",
    "            label.append(np.argmax(y_pred[i])+1)\n",
    "    \n",
    "    dict = {'image_id': image_id, 'label': label}\n",
    "    if get_pred:\n",
    "        for i in range(NUM_CLASSES):\n",
    "            dict['class_{}'.format(i+1)] = y_class[i]\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = get_result()\n",
    "df = pd.DataFrame(dict)\n",
    "df.to_csv(\"efnB6_multi_label_combine_tta.csv\", index = False, header = False, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
